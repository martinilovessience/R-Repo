{
    "collab_server" : "",
    "contents" : "#### Bayer AG Data Science Interview ####\n### Sentiment analysis\n\n\ninstall.packages(\"ggplot2\")\ninstall.packages(\"magrittr\")\ninstall.packages(\"dplyr\")\ninstall.packages(c('e1071', 'rpart'))\ninstall.packages(\"tibble\")\ninstall.packages(\"dplyr\")\ninstall.packages(\"tm\")\n\nlibrary(RTextTools)\nlibrary(dplyr)\nlibrary(e1071)\nlibrary(rpart)\nlibrary(tm)\nlibrary(openxlsx)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nsetwd(\"/Users/martinkurek/Documents/R Repo/bayer_case\")\n\n\n## Part 1: Vizualise distribution of sentiments\n\n# Read in data\nsm_data <- read.xlsx(\"data/sentences_with_sentiment.xlsx\")\nhist_data <- as.data.frame(sm_data[, 3:5])\n\n\n## Create the dataframe for historgram\nSentiment <- c(\"Positive\", \"Negative\", \"Neutral\")\nCount <-\n  c(sum(hist_data$Positive),\n    sum(hist_data$Negative),\n    sum(hist_data$Neutral))\ntotal_count = sum(hist_data$Positive) + sum(hist_data$Negative) + sum(hist_data$Neutral)\nPercent <- c(paste(round((\n  sum(hist_data$Positive) / total_count\n) * 100), \"%\"),\npaste(round((\n  sum(hist_data$Negative) / total_count\n) * 100), \"%\"),\npaste(round((\n  sum(hist_data$Neutral) / total_count\n) * 100), \"%\"))\nhist_sum <- data.frame(Sentiment, Count, Percent)\n\n#Plot distribution with ggplot\n\ng <- ggplot(hist_sum, aes(Sentiment, Count))\ng + geom_col(fill = \"blue\") + geom_label(label = Percent)\n\n\n\n### Part 2: Sentiment Analysis\n\n## Declare useful functions\n\n# List of words function can be used for selection of features but was on purpose not applied due to lack of words.\n#  listOfWords<- {c(\n#    \"pmlast\"\n#  )}\n\n\n\n# Transform binary scema into nominal\nassignSentiment <- function(x) {\n  i = 1\n  y <- data.frame()\n  \n  for (i in i:nrow(hist_data)) {\n    if (hist_data[i, 1] == 1) {\n      y[i, 1] = \"Positive\"\n    } else if (hist_data[i, 2] == 1) {\n      y[i, 1] = \"Negative\"\n    } else {\n      y[i, 1] = \"Neutral\"\n    }\n  }\n  \n  return(y)\n}\n\n\n# Generate Document Term Matrix with specified text preprocessing criteria\n\ngenerateDTM <- function(z) {\n  y <- VCorpus(VectorSource(z[, 1]))\n  \n  y <- tm_map(y, content_transformer(tolower))\n  \n  y <- tm_map(y, removeNumbers)\n  \n  y <- tm_map(y, removePunctuation)\n  \n  y <- tm_map(y, removeWords, stopwords(\"english\"))\n  \n  #y <- tm_map(y, removeWords, listOfWords)\n  \n  y <- tm_map(y, stripWhitespace)\n  \n  y <- DocumentTermMatrix(x = y)\n  \n  return(y)\n}\n\n# Generate Document Term Matrix with same criteria\n\ngenerateCorpus <- function(z) {\n  y <- VCorpus(VectorSource(z[, 1]))\n  \n  y <- tm_map(y, content_transformer(tolower))\n  \n  y <- tm_map(y, removeNumbers)\n  \n  y <- tm_map(y, removePunctuation)\n  \n  y <- tm_map(y, removeWords, stopwords(\"english\"))\n  \n  #y <- tm_map(y, removeWords, listOfWords)\n  \n  y <- tm_map(y, stripWhitespace)\n  \n  return(y)\n}\n\n# Load data\n\ntdata <- as.data.frame(sm_data[, 2])\nsent <- assignSentiment(hist_data)\n\nfull_data <- cbind(tdata, sent)\n\n\n\n# Treat rss_trn as tdata (Trainingdata) and rss_rel as sent\n\n############ Text Mining ###########\n\ndtm.train <- generateDTM(tdata)\n\ncorupus.train <- generateCorpus(tdata)\n\n##Split into Train & Testset\n\nindex <- 1:nrow(sent)\n\n# Set Parameter for sampling (75% Training, 25% Testing) by defining and applying index\n\ntestindex <- sample(index, trunc(length(index)) / 1.333)\n\ndf.train <- sent[testindex,]\ndf.test <- sent[-testindex,]\n\ntrainset <- dtm.train[testindex,]\ntestset <- dtm.train[-testindex,]\n\ncorpus.ts <- corupus.train[testindex]\ncorpus.tss <- corupus.train[-testindex]\n\n## Feature selection by chosing frequency interval\n\ndim(trainset)\n\n# finding terms with lowest 2 and highest 5 frequency\nft <- findFreqTerms(trainset, 2, 5)\n\nlength((ft))\n\ntrainset <-\n  DocumentTermMatrix(corpus.ts, control = list(dictionary = ft))\ntestset <-\n  DocumentTermMatrix(corpus.tss, control = list(dictionary = ft))\n\n\n\n##Train model with SVM \n\ncontainer <-\n  create_container(trainset,\n                   df.train,\n                   trainSize = 1:nrow(trainset),\n                   virgin = FALSE)\n\n##Linear Kernel because values are either 0 or 1 and evaluation of applying both showed linear fits better\npred.model <-\n  train_model(container = container,\n              algorithm = \"SVM\",\n              kernel = \"linear\")\n\n\npredicted <- predict(pred.model, newdata = testset)\n\n\n## Evaluate Model\ntable <- table(\"Predictions\" = predicted, \"Actual\" = df.test)\n\n#Print Confusion Matrix\nprint(table)\n\n#Precision\nnB_precision_ng <- round(table[1, 1] / sum(table[, 1]), 2)\nnB_precision_nt <- round(table[2, 2] / sum(table[, 2]), 2)\nnB_precision_p <- round(table[3, 3] / sum(table[, 3]), 2)\n\n#Recall\nnB_recall_ng <- round(table[1, 1] / sum(table[1, ]), 2)\nnB_recall_nt <- round(table[2, 2] / sum(table[2, ]), 2)\nnB_recall_p <- round(table[3, 3] / sum(table[3, ]), 2)\n\n\n#Print Precision and Recall- Measures\n\nprint(c(\"Precision class 'Negative':\", nB_precision_ng))\nprint(c(\"Recall class 'Negative':\", nB_recall_ng))\nprint(c(\"Precision class 'Positive':\", nB_precision_p))\nprint(c(\"Recall class 'Positive':\", nB_recall_p))\nprint(c(\"Precision class 'Neutral':\", nB_precision_nt))\nprint(c(\"Recall class 'Neutral':\", nB_recall_nt))\n\n#Print overall accuracy\nprint(paste(\n  \"Accuracy:\",\n  (\n    nB_precision_ng + nB_precision_nt + nB_precision_p + nB_recall_ng + nB_recall_nt + nB_recall_p\n  ) / 6\n))",
    "created" : 1586119281900.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "891295369",
    "id" : "65083047",
    "lastKnownWriteTime" : 1586184896,
    "last_content_update" : 1586184896517,
    "path" : "~/Documents/R Repo/bayer_case/task/sent_analysis.R",
    "project_path" : "task/sent_analysis.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}